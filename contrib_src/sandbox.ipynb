{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates how use the model api to run predictions and get information from the model. You can use it as basis to write your own experiements using the model in this container.\n",
    "\n",
    "To start, import _modelapi.model_, which will give us access to the api of the model in this container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from modelapi import model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# other helpful imports for this demo\n",
    "import h5py\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Various ways of handing data to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can either load the necessary input for the prediction from a file:\n",
    "input = 'sample_data/sample.json'\n",
    "# or assemble a dictionary for yourself \n",
    "input_dict = {\"t1\":{},\"t2\":{},\"flair\":{},\"t1c\":{}}\n",
    "# mandatory: fileurl for each input!\n",
    "input_dict[\"t1\"][\"fileurl\"] = 'sample_data/patient_1/t1.nii.gz'\n",
    "# mandatory: format for each input, be aware that this has to be a list:\n",
    "input_dict[\"t1\"][\"format\"] = [\"application/nii-gzip\"]\n",
    "# and so on for each other input.. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(input, \"r\") as f:\n",
    "    input_dict_from_json = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can then simply pass your input to the model:\n",
    "result = model.predict(input_dict_from_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's see what the output contains:\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Recover a prediction from the h5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recover prediction from h5 file\n",
    "resultFile = result[\"output\"][0][\"prediction\"].replace(\"api\", \"\")\n",
    "f = h5py.File(resultFile, 'r')\n",
    "print(list(f.keys()))\n",
    "# load the actual prediction and check for correct shape\n",
    "prediction = f[\"Segmentation\"]\n",
    "print('Shape of prediction is: {}'.format(prediction.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just plot one slice to see if it returns a sensible result \n",
    "plt.imshow(prediction[90], aspect=0.5)\n",
    "print(prediction[90].max(), prediction[90].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Saving the result as a Nifti-1 file so we can use it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, we load the metadata from one of the input images to populate the header:\n",
    "img = nib.load('sample_data/patient_1/flair.nii.gz')\n",
    "affine = img.affine\n",
    "header = img.header\n",
    "seg_nifti = nib.Nifti1Image(prediction, affine, header)\n",
    "nib.save(seg_nifti,'sample_data/patient_1/segmentation.nii.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ask the model for a list of sample data, then run a prediction on the first of the sample dataset, and then display the prediction result output.\n",
    "\n",
    "If the model does not provide any sample data, print an error message (this part also shows how to read meta info - like the model's name - from the models config)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = model.get_samples()\n",
    "if len(samples[\"files\"]) > 0:\n",
    "    inputFile = samples[\"folder\"] + \"/\" + samples[\"files\"][0]\n",
    "    result = model.predict(inputFile)\n",
    "    for i, output in enumerate(result[\"output\"]):\n",
    "        print(\"\\n\" + result[\"model\"][\"name\"] + \" Output \" + str(i) + \":\")\n",
    "        print(\"  Type:  \" + output[\"type\"])\n",
    "        print(\"  Name:  \" + output[\"name\"])\n",
    "        print(\"  Shape: \" + str(output[\"shape\"]))\n",
    "        print(\"  Prediction:\")\n",
    "        if output[\"type\"] in [\"mask_image\", \"image\"]:\n",
    "            # if output seems to be an image, try displaying it nicely with PIL\n",
    "            try:\n",
    "                import PIL\n",
    "                image = PIL.Image.fromarray(output[\"prediction\"])\n",
    "                display(image)\n",
    "            except:\n",
    "                display(output[\"prediction\"])\n",
    "        else:\n",
    "            display(output[\"prediction\"])\n",
    "else:\n",
    "    model_name = model.get_config()[\"meta\"][\"name\"]\n",
    "    print(model_name + \" does not provide any sample data, please try your own data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
